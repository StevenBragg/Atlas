#!/bin/bash
# ============================================
# Atlas + OpenClaw Entrypoint for Salad Cloud
# ============================================
# 1. Starts OpenClaw gateway (with Claude) immediately
# 2. Installs heavy Python deps (PyTorch, CuPy) at runtime
# 3. Then starts the Atlas GPU learning service
# ============================================

set -e

echo "============================================"
echo " ATLAS + OpenClaw on Salad Cloud"
echo "============================================"

# --- Generate OpenClaw .env from container env vars ---
OPENCLAW_ENV_FILE="${OPENCLAW_HOME:-/home/atlas/.openclaw}/.env"

echo "# Auto-generated by Atlas entrypoint" > "${OPENCLAW_ENV_FILE}"

# LLM API keys - pass any of these via Salad Cloud env vars
[ -n "${ANTHROPIC_API_KEY}" ]   && echo "ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}" >> "${OPENCLAW_ENV_FILE}"
[ -n "${OPENAI_API_KEY}" ]      && echo "OPENAI_API_KEY=${OPENAI_API_KEY}" >> "${OPENCLAW_ENV_FILE}"
[ -n "${GEMINI_API_KEY}" ]      && echo "GEMINI_API_KEY=${GEMINI_API_KEY}" >> "${OPENCLAW_ENV_FILE}"
[ -n "${OPENROUTER_API_KEY}" ]  && echo "OPENROUTER_API_KEY=${OPENROUTER_API_KEY}" >> "${OPENCLAW_ENV_FILE}"

# Gateway auth
[ -n "${OPENCLAW_GATEWAY_TOKEN}" ]    && echo "OPENCLAW_GATEWAY_TOKEN=${OPENCLAW_GATEWAY_TOKEN}" >> "${OPENCLAW_ENV_FILE}"
[ -n "${OPENCLAW_GATEWAY_PASSWORD}" ] && echo "OPENCLAW_GATEWAY_PASSWORD=${OPENCLAW_GATEWAY_PASSWORD}" >> "${OPENCLAW_ENV_FILE}"

# Channel tokens - pass these to enable channels
[ -n "${TELEGRAM_BOT_TOKEN}" ]  && echo "TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}" >> "${OPENCLAW_ENV_FILE}"
[ -n "${DISCORD_BOT_TOKEN}" ]   && echo "DISCORD_BOT_TOKEN=${DISCORD_BOT_TOKEN}" >> "${OPENCLAW_ENV_FILE}"
[ -n "${SLACK_BOT_TOKEN}" ]     && echo "SLACK_BOT_TOKEN=${SLACK_BOT_TOKEN}" >> "${OPENCLAW_ENV_FILE}"

echo "OpenClaw .env written to ${OPENCLAW_ENV_FILE}"

# --- Start OpenClaw gateway immediately (lightweight, no GPU deps needed) ---
OPENCLAW_PORT="${OPENCLAW_GATEWAY_PORT:-18789}"
echo "Starting OpenClaw gateway on port ${OPENCLAW_PORT}..."

openclaw gateway \
  --port "${OPENCLAW_PORT}" \
  --allow-unconfigured \
  --bind lan \
  > /data/logs/openclaw.log 2>&1 &

OPENCLAW_PID=$!
echo "OpenClaw gateway started (PID: ${OPENCLAW_PID})"

# Graceful shutdown: forward signals to both processes
ATLAS_PID=""
cleanup() {
  echo "Shutting down..."
  [ -n "${ATLAS_PID}" ] && kill "${ATLAS_PID}" 2>/dev/null || true
  kill "${OPENCLAW_PID}" 2>/dev/null || true
  [ -n "${ATLAS_PID}" ] && wait "${ATLAS_PID}" 2>/dev/null || true
  wait "${OPENCLAW_PID}" 2>/dev/null || true
  exit 0
}
trap cleanup SIGTERM SIGINT

# --- Install heavy Python deps at runtime ---
# This keeps the Docker image small (~500MB) for fast Salad allocation.
# PyTorch + CuPy are ~4GB and would make the image too large for
# residential nodes to pull quickly.
echo "============================================"
echo " Installing GPU dependencies..."
echo "============================================"

echo "Installing PyTorch with CUDA 12.1 support..."
pip3 install --no-cache-dir \
  torch torchvision torchaudio \
  --index-url https://download.pytorch.org/whl/cu121 \
  2>&1 | tail -1

echo "Installing CuPy for GPU-accelerated NumPy..."
pip3 install --no-cache-dir cupy-cuda12x \
  2>&1 | tail -1

echo "============================================"
echo " GPU dependencies installed successfully!"
echo "============================================"

# --- Start Atlas service ---
echo "Starting Atlas service..."
python3 -m cloud.salad_service &
ATLAS_PID=$!

# Wait for Atlas (foreground process)
wait "${ATLAS_PID}"
